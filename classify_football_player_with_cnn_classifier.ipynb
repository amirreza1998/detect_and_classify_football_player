{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnKmAN7eB6_n",
        "outputId": "54347e1f-07f5-4554-8cb3-a5553371ce6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dirpath = 'drive/MyDrive/vision project/xmls'  # The directory where the xml file was originally stored\n",
        "frame_dirpath = 'drive/MyDrive/vision project/frames/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `load database`"
      ],
      "metadata": {
        "id": "FaUT1DQu93fX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mzh1GPUCVi_H"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "dirpath = 'drive/MyDrive/vision project/xmls'  # The directory where the xml file was originally stored\n",
        "# newdir = 'E:/univarsity/machine vision/final_project/frames/New Folder'  # edit the txt directory formed after the label\n",
        "player_label=np.array([])\n",
        "player_image=np.array([])\n",
        "a_3d_array = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "j=0\n",
        "for fp in os.listdir(dirpath):\n",
        "    root = ET.parse(os.path.join(dirpath, fp)).getroot()\n",
        "\n",
        "    xmin, ymin, xmax, ymax = 0, 0, 0, 0\n",
        "    sz = root.find('size')\n",
        "    width = float(sz[0].text)\n",
        "    height = float(sz[1].text)\n",
        "    filename = root.find('filename').text\n",
        "    im = Image.open(frame_dirpath + filename)\n",
        "    img = cv2.imread(frame_dirpath + filename)\n",
        "    i=0\n",
        "    for child in root.findall('object'):  # Found all the boxes in the image\n",
        "        #make image array\n",
        "        sub = child.find('bndbox')  # Found the label value of the box and read it\n",
        "        xmin = float(sub[0].text)\n",
        "        ymin = float(sub[1].text)\n",
        "        xmax = float(sub[2].text)\n",
        "        ymax = float(sub[3].text)\n",
        "        x_center = (xmin + xmax) / (2 * width)\n",
        "        y_center = (ymin + ymax) / (2 * height)\n",
        "\n",
        "        im1 = im.crop((xmin, ymin, xmax, ymax))\n",
        "        cropped_image = img[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
        "        dim=(100,100)\n",
        "        resized = cv2.resize(cropped_image, dim, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        if j>1:\n",
        "            player_image = np.concatenate((player_image,  [resized]), axis=0)\n",
        "        if j == 1:\n",
        "            player_image = np.stack((player_image, resized))\n",
        "            j = j + 1\n",
        "        if j == 0:\n",
        "            player_image = resized\n",
        "            j = j + 1\n",
        "\n",
        "        name = root.find('name')\n",
        "        if child[0].text=='red':\n",
        "            player_label=np.append(player_label,0)\n",
        "        if child[0].text=='blue':\n",
        "            player_label=np.append(player_label,1)\n",
        "        if child[0].text=='yellow':\n",
        "            player_label=np.append(player_label,2)\n",
        "    player_image=np.array(player_image)\n",
        "print(player_image.shape)\n",
        "print(player_label.shape)\n",
        "np.save(\"player_image.npy\", player_image)\n",
        "np.save(\"player_label.npy\", player_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load libraries and seprate test and train data\n"
      ],
      "metadata": {
        "id": "PjjM6KLX-K9t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joUpqOQVHfS_"
      },
      "outputs": [],
      "source": [
        "# %tensorflow_version 1.x\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input ,Dense,Activation, Conv2D,AveragePooling2D,Flatten\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "get_ipython().magic(u'matplotlib inline')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iWnwoq1HzRl",
        "outputId": "493209d7-5c43-4732-ab1b-aa3b345a5743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "player_image shape is (1073, 100, 100, 3)\n",
            "player_label shape is (1073,)\n",
            "train_x shape is (965, 100, 100, 3)\n",
            "train_y shape is (965,)\n",
            "test_x shape is (108, 100, 100, 3)\n",
            "test_y shape is (108,)\n"
          ]
        }
      ],
      "source": [
        "print(\"player_image shape is {}\".format( player_image.shape ))\n",
        "print(\"player_label shape is {}\".format( player_label.shape ))\n",
        "\n",
        "x_train, x_test, y_train, y_test  = train_test_split(player_image, player_label , test_size=0.1, shuffle=True, random_state=5)\n",
        "print(\"train_x shape is {}\".format( x_train.shape ))\n",
        "print(\"train_y shape is {}\".format( y_train.shape ))\n",
        "print(\"test_x shape is {}\".format( x_test.shape ))\n",
        "print(\"test_y shape is {}\".format( y_test.shape ))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# normalize input image of x_train and x_test"
      ],
      "metadata": {
        "id": "_q45Hmj0-UGa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUYpxJzQKXoQ",
        "outputId": "c38d922c-aee1-4eac-f3e1-054310dc3642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max value of x is 1.0 and min value is 0.0 \n",
            "unique value of y_train [0. 1. 2.]\n"
          ]
        }
      ],
      "source": [
        "image_size = x_train.shape[0]\n",
        "# print(x_train)\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255\n",
        "print(f\"max value of x is {x_train.max()} and min value is {x_train.min()} \")\n",
        "print(f\"unique value of y_train {np.unique(y_train)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# categorical class label\n",
        "we use label to create matrix for them \n",
        "it mean get value integer that is label of class and make it vector that spcial component of this vector is 1 for spcial class number "
      ],
      "metadata": {
        "id": "Qg5sb4lPD82I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxEJobnrJlYH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef0aa01-6bd0-4e84-e96e-68e1882c2cab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train shape after categorical it\n"
          ]
        }
      ],
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "print(\"y_train shape after categorical it\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# make datagenerator \n",
        "datagenerator make diffrent type of data from our data by change angle of image by rotation or shifting image to right or left or zomming or fliping or ..."
      ],
      "metadata": {
        "id": "J27a5f2DEYs8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJB35YjSES-I"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "          rotation_range=30,\n",
        "          width_shift_range=0.2,\n",
        "          height_shift_range=0.2,\n",
        "          zoom_range=0.2,\n",
        "          horizontal_flip=True,\n",
        "          fill_mode='nearest')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1_ulnssyEtl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# build and compile cnn model "
      ],
      "metadata": {
        "id": "S8hhgitaEtqu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDJYK6fjFoKw"
      },
      "outputs": [],
      "source": [
        "def build_model(input_shape):\n",
        "  \n",
        "  x_input = Input(shape =input_shape,name = 'input')\n",
        "\n",
        "  x = Conv2D(filters = 16,kernel_size = (2,2), strides = 1, padding = 'valid',name = 'conv2')(x_input)\n",
        "  x = Activation('relu')(x)\n",
        "  x = AveragePooling2D(pool_size =2,strides = 2,name = 'pad2')(x)\n",
        "\n",
        "  x = Conv2D(filters = 8,kernel_size = (2,2), strides = 1, padding = 'valid',name = 'conv2a')(x_input)\n",
        "  x = Activation('relu')(x)\n",
        "  x = AveragePooling2D(pool_size =2,strides = 2,name = 'pad2')(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "\n",
        "  x = Dense(units = 120, name = 'fc_1')(x)\n",
        "\n",
        "  x = Activation('relu', name = 'relu_1')(x)\n",
        "  # x = Dropout(rate = 0.5)\n",
        "\n",
        "  x = Dense(units = 84, name = 'fc_2')(x)\n",
        "  x = Activation('relu', name = 'relu_2')(x)\n",
        "  # x = Dropout(rate = 0.5)\n",
        "\n",
        "\n",
        "  outputs = Dense(units = 3,name = 'softmax', activation='softmax')(x)\n",
        "  \n",
        "  model = Model(inputs = x_input, outputs = outputs)\n",
        "  model.summary()\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xIdALXlGC3W",
        "outputId": "ac3c42d1-9b9a-45c5-8007-0e8f82ba08a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " conv2a (Conv2D)             (None, 99, 99, 8)         104       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 99, 99, 8)         0         \n",
            "                                                                 \n",
            " pad2 (AveragePooling2D)     (None, 49, 49, 8)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 19208)             0         \n",
            "                                                                 \n",
            " fc_1 (Dense)                (None, 120)               2305080   \n",
            "                                                                 \n",
            " relu_1 (Activation)         (None, 120)               0         \n",
            "                                                                 \n",
            " fc_2 (Dense)                (None, 84)                10164     \n",
            "                                                                 \n",
            " relu_2 (Activation)         (None, 84)                0         \n",
            "                                                                 \n",
            " softmax (Dense)             (None, 3)                 255       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,315,603\n",
            "Trainable params: 2,315,603\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = build_model(input_shape=(100,100,3))\n",
        "model.compile(optimizer = 'adam',loss = 'categorical_crossentropy' ,metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fit and train our model \n",
        "now by using our train dataset fit our model to train dataset and train on that dataset"
      ],
      "metadata": {
        "id": "dlSDYu4HFMnk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc0eI5IRGkIn",
        "outputId": "82960faa-e392-4cba-eca0-9ad01234896c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "15/15 [==============================] - 19s 265ms/step - loss: 1.2428 - accuracy: 0.5683 - val_loss: 0.5247 - val_accuracy: 0.9074\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 3s 177ms/step - loss: 0.4707 - accuracy: 0.8701 - val_loss: 0.2390 - val_accuracy: 0.9259\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 0.2825 - accuracy: 0.9256 - val_loss: 0.1201 - val_accuracy: 0.9630\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 3s 189ms/step - loss: 0.1945 - accuracy: 0.9445 - val_loss: 0.0802 - val_accuracy: 0.9815\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 3s 208ms/step - loss: 0.1635 - accuracy: 0.9445 - val_loss: 0.0469 - val_accuracy: 0.9907\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 3s 182ms/step - loss: 0.1505 - accuracy: 0.9534 - val_loss: 0.0482 - val_accuracy: 0.9815\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 3s 181ms/step - loss: 0.1463 - accuracy: 0.9434 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 3s 189ms/step - loss: 0.0853 - accuracy: 0.9734 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 2s 145ms/step - loss: 0.1208 - accuracy: 0.9623 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 3s 187ms/step - loss: 0.1018 - accuracy: 0.9634 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 0.1032 - accuracy: 0.9589 - val_loss: 0.0183 - val_accuracy: 0.9907\n",
            "Epoch 12/20\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 0.0707 - accuracy: 0.9745 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 0.0939 - accuracy: 0.9678 - val_loss: 0.0674 - val_accuracy: 0.9815\n",
            "Epoch 14/20\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.1499 - accuracy: 0.9567 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 0.0917 - accuracy: 0.9667 - val_loss: 0.0933 - val_accuracy: 0.9815\n",
            "Epoch 16/20\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 0.0964 - accuracy: 0.9656 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 0.0794 - accuracy: 0.9789 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 0.0686 - accuracy: 0.9845 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 0.0778 - accuracy: 0.9745 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "15/15 [==============================] - 2s 127ms/step - loss: 0.0518 - accuracy: 0.9878 - val_loss: 0.0049 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# model.fit(x = x_train, y= y_train , batch_size=5, epochs = 4)\n",
        "batch_size = 64\n",
        "H = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "  validation_data=(x_test, y_test),                       \n",
        "\tsteps_per_epoch=len(y_train) // batch_size, epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# show result of classification with some samples"
      ],
      "metadata": {
        "id": "QUd5wUG7E2E3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5L55PQEDMtln"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "i=0\n",
        "while i<10:\n",
        "    j=int(random.random()*100)\n",
        "    sample = x_test[j]\n",
        "    print(x_test[j].shape)\n",
        "    sample_show = sample.reshape((100,100,3))\n",
        "    plt.figure(figsize=(3,3))\n",
        "    plt.imshow(sample_show , cmap='gray')\n",
        "    plt.show()\n",
        "    batch = np.expand_dims(sample, axis=0)\n",
        "    prediction = model.predict(batch)\n",
        "    print(prediction)\n",
        "    print(prediction[0])\n",
        "    print(   np.argmax(prediction[0])    )  \n",
        "    i=i+1\n",
        "    if np.argmax(prediction[0])==0:\n",
        "      print('blue')\n",
        "    if np.argmax(prediction[0])==1:\n",
        "      print('red')\n",
        "    if np.argmax(prediction[0])==2:\n",
        "      print('refree')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# calculate accurcy in test dataset"
      ],
      "metadata": {
        "id": "DMV2eAo_Fkd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print(f\"accuricy is {acc*100}%\")\n",
        "print(f\"loss score is {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFMYoUGnFkm2",
        "outputId": "83f6484a-1d8e-43a2-8283-c9d159bb21b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "accuricy is 100.0%\n",
            "loss score is 0.004909067414700985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mapping video with classification\n",
        "in this part we get video of players and start to detect players in each frame and then cut players image and give it to model that trained above after that if it is blue shirt player we add corresponding blue spot in 2d map of mapping video at registered place in 2d map if it's red tishirt player add red spot and if it is refree add yellow spot"
      ],
      "metadata": {
        "id": "p2Apj8slXErT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import cv2\n",
        "import cv2 as cv\n",
        "import argparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "\n",
        "video_save_path = 'drive/MyDrive/vision project/result.avi'#output video path\n",
        "arg_input='drive/MyDrive/vision project/output.mp4'#input video path\n",
        "\n",
        "backSub = cv.createBackgroundSubtractorMOG2()\n",
        "\n",
        "# backSub = cv.createBackgroundSubtractorKNN()\n",
        "capture = cv.VideoCapture(cv.samples.findFileOrKeep(arg_input))\n",
        "\n",
        "\n",
        "if not capture.isOpened():\n",
        "    print('Unable to open: ' +arg_input)\n",
        "    exit(0)\n",
        "\n",
        "\n",
        "##point creation\n",
        "points1 = np.array([(164, 150),\n",
        "                    (886, 150),\n",
        "                    (525, 0),\n",
        "                    (525, 700)]).astype(np.float32)\n",
        "\n",
        "points2 = np.array([(149, 165),\n",
        "                    (1140, 115),\n",
        "                    (640, 110),\n",
        "                    (875, 780)]).astype(np.float32)\n",
        "\n",
        "\n",
        "## hemographic trasnform\n",
        "H = cv2.getPerspectiveTransform(points2, points1)\n",
        "print(H)\n",
        "z=0\n",
        "\n",
        "#define video\n",
        "I2 = cv2.imread('2D_field.png')\n",
        "# w = I2.shape[1]\n",
        "# h = I2.shape[0]\n",
        "w=1050\n",
        "h=700\n",
        "out = cv2.VideoWriter(video_save_path, cv2.VideoWriter_fourcc(*'MJPG'), 10.0, (w, h))\n",
        "\n",
        "#start reading image\n",
        "while True:\n",
        "    ret, frame = capture.read()\n",
        "    if frame is None:\n",
        "        break\n",
        "    # frame=cv2.GaussianBlur(frame, (3,3), 0);\n",
        "    fgMask = backSub.apply(frame)\n",
        "    ret, T = cv2.threshold(fgMask, 254, 255, cv2.THRESH_BINARY)#thsi code for destroy shadows\n",
        "\n",
        "    ## erosion and dilation\n",
        "    # erosion_kernel = np.ones((15,5), np.uint8);\n",
        "    erosion_kernel=np.array([[0 ,0 ,1 ,0 ,0],\n",
        "                            [0 ,0 ,1 ,1 ,0],\n",
        "                            [0 ,1 ,1 ,1 ,0],\n",
        "                            [1, 1, 1, 1, 1],\n",
        "                            [1, 1, 1, 1, 1],\n",
        "                            [1, 1, 1, 1, 1],\n",
        "                            [1, 1, 1, 1, 1],\n",
        "                            [0, 1, 1, 1, 0],\n",
        "                            [0, 0, 1, 1, 0],\n",
        "                            [0 ,0 ,1 ,0 ,0]],np.uint8)\n",
        "    dilat_kernel = np.array([[0, 0, 1, 0, 0],\n",
        "                               [0, 0, 1, 1, 0],\n",
        "                               [0, 1, 1, 1, 0],\n",
        "                               [1, 1, 1, 1, 1],\n",
        "                               [1, 1, 1, 1, 1],\n",
        "                               [1, 1, 1, 1, 1],\n",
        "                               [1, 1, 1, 1, 1],\n",
        "                               [0, 1, 1, 1, 0],\n",
        "                               [0, 0, 1, 1, 0],\n",
        "                               [0, 0, 1, 0, 0]], np.uint8)\n",
        "    # dilat_kernel= np.ones((15, 5), np.uint8);\n",
        "    erosioned = cv2.erode(T, erosion_kernel);\n",
        "    dilated=cv2.dilate(erosioned,dilat_kernel);\n",
        "\n",
        "    n2,C2, stats2, centroids2=cv2.connectedComponentsWithStats(dilated)\n",
        "\n",
        "    #put rules on connected component siza\n",
        "    delet_array=list()\n",
        "    n2new=n2\n",
        "    # print(stats2)\n",
        "    # print(stats2.shape)\n",
        "    for i in range(0, n2 ):\n",
        "        if stats2[i][4] < 150:\n",
        "           # centroids2\n",
        "           delet_array.append(i)\n",
        "\n",
        "           n2new=n2new-1\n",
        "    centroids2new = np.delete(centroids2, delet_array,0)\n",
        "    stats2=np.delete(stats2,delet_array, axis=0)\n",
        "\n",
        "    ##delet connect componet that are not in yard\n",
        "    # y meghdar avalie centroid ast va x meghdar dovom\n",
        "    n2new1=n2new\n",
        "    delet_array=list()\n",
        "    for i in range(0, n2new - 1):\n",
        "        if ((1225 - 20) / (60 - 120))*(centroids2new[i][1] - 60) + 1225 > centroids2new[i][0]:\n",
        "            delet_array.append(i)\n",
        "            n2new1=n2new1-1\n",
        "\n",
        "    centroids2new = np.delete(centroids2new, delet_array,0)\n",
        "    stats2 = np.delete(stats2, delet_array, axis=0)\n",
        "\n",
        "    ## put text on frames\n",
        "    cv.rectangle(frame, (10, 2), (100, 20), (255, 255, 255), -1)\n",
        "    cv.putText(frame, str(capture.get(cv.CAP_PROP_POS_FRAMES)), (15, 15),\n",
        "               cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
        "    cv.rectangle(fgMask, (10, 2), (100, 20), (255, 255, 255), -1)\n",
        "    cv.putText(fgMask, str(n2new+1), (15, 15),\n",
        "               cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
        "    cv.rectangle(dilated, (10, 2), (100, 20), (255, 255, 255), -1)\n",
        "    cv.putText(dilated, str(n2new1+1), (15, 15),\n",
        "               cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))\n",
        "\n",
        "\n",
        "    ##show images\n",
        "    cv2.line(frame,(1225, 60),(20, 120),(255,0,255,1),2)\n",
        "\n",
        "\n",
        "    ## bird eye\n",
        "    I1 = cv2.imread('drive/MyDrive/vision project/2D_field.png')\n",
        "    # output_size=(I1.shape[0],I1.shape[1])\n",
        "    eye_bird=I1\n",
        "    i=1\n",
        "    while i<n2new1:\n",
        "        location = np.array([(centroids2new[i][0].astype(np.int32)),\n",
        "                   (centroids2new[i][1].astype(np.int32)),\n",
        "                   (1)])\n",
        "\n",
        "        cropped_image12 = frame[int(stats2[i][1]):int(stats2[i][1]+stats2[i][3]),int(stats2[i][0]):int(stats2[i][0]+stats2[i][2])]\n",
        "        print(cropped_image12.shape)\n",
        "        dim=(100,100)\n",
        "        cropped_resized = cv2.resize(cropped_image12, dim, interpolation=cv2.INTER_AREA)\n",
        "        print(cropped_resized.shape)\n",
        "        batch = np.expand_dims(cropped_resized, axis=0)\n",
        "        prediction = model.predict(batch)\n",
        "        print(prediction[0])\n",
        "        print(   np.argmax(prediction[0])    )\n",
        "\n",
        "        location=location.transpose()\n",
        "        location=np.dot(H,location)\n",
        "\n",
        "        position1=location[0]/location[2]\n",
        "        position2=location[1]/location[2]\n",
        "        if np.argmax(prediction[0])==0:\n",
        "          cv2.circle(eye_bird,(position1.astype(np.int32),position2.astype(np.int32)),10,(0, 0, 255,1),-1);\n",
        "        if np.argmax(prediction[0])==1:\n",
        "          cv2.circle(eye_bird,(position1.astype(np.int32),position2.astype(np.int32)),10,(255,0,0,1),-1);\n",
        "        if np.argmax(prediction[0])==2:\n",
        "          cv2.circle(eye_bird,(position1.astype(np.int32),position2.astype(np.int32)),10,(255,255,0,1),-1);\n",
        "        i=i+1\n",
        "    out.write(eye_bird)\n",
        "    keyboard = cv.waitKey(30)\n",
        "    if keyboard == 'q' or keyboard == 27:\n",
        "        break\n",
        "out.release()\n"
      ],
      "metadata": {
        "id": "cAKW9cDjX0iu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}